{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRIS Invoice Recognition Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string extraction tools\n",
    "import re\n",
    "from Levenshtein import distance\n",
    "\n",
    "# opencv\n",
    "import cv2\n",
    "\n",
    "# images \n",
    "from wand.image import Image\n",
    "from wand.color import Color\n",
    "try:\n",
    "    from PIL import Image as P_image\n",
    "except ImportError:\n",
    "    import Image as P_image\n",
    "\n",
    "# ocr engine\n",
    "import pytesseract\n",
    "\n",
    "# others\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -t onedork -f roboto -fs 10 -tfs 11 -T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please change your directory to computer_vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite:\n",
    "\n",
    "- Text extraction process:\n",
    "    1. pdfminer.six pip\n",
    "    2. regex\n",
    "    3. pip install python-Levenshtein\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "- OCR process\n",
    "    1. PDF to Image:\n",
    "        - ImageMagick windows, put it into path and name it as MAGICK_HOME\n",
    "        - ghostscript windows\n",
    "        - wand pip\n",
    "    2. Opencv\n",
    "    3. tesseract windows\n",
    "    4. pytesseract pip\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process:\n",
    "\n",
    "- if it's a PDF file?\n",
    "\n",
    "    - If yes, can we extract the text through pdfminer without error?\n",
    "        - if yes, use pdfminer\n",
    "        - if no, we convert it into PNGs, do some opencv processing and start the OCR process\n",
    "<br><br>\n",
    "- We have the text file\n",
    "- We use regex and Levenshtein distance to extract text\n",
    "- We score the output\n",
    "- We go back to the OCR & pdfminder stepes and use another way trying to get a higher score\n",
    "<br><br>\n",
    "\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR\n",
    "\n",
    "1. PDF to Image\n",
    "2. Opencv preprocessing\n",
    "3. Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_process(filename, resolution=450):\n",
    "    \"\"\" Convert a PDF into images, \n",
    "        preprocess them using opencv, \n",
    "        and then feed them into Tesseract ocr engine.\n",
    "    \"\"\"\n",
    "    txt = \"\"\n",
    "    all_pages = Image(filename=filename, resolution=resolution)\n",
    "    for i, page in enumerate(all_pages.sequence):\n",
    "        with Image(page) as img:\n",
    "            img.format = 'png'\n",
    "            img.background_color = Color('white')\n",
    "            img.alpha_channel = 'remove'\n",
    "\n",
    "            image_filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "            image_filename = '{}-{}.png'.format(image_filename, i)\n",
    "            path_filename = os.path.join('converted_image', image_filename)\n",
    "            \n",
    "            try:\n",
    "                os.mkdir('converted_image')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            img.save(filename=path_filename) # save it to the output path\n",
    "            \n",
    "            # 1. 转化为灰度图\n",
    "            im = cv2.imread(path_filename)\n",
    "            im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # 这个在Invoice上用不多。当我们需要做Receipt时，需要这个。\n",
    "            \n",
    "#             # 2. 用adaptive threshold对图像进行二值化处理\n",
    "#             im_inv = cv2.adaptiveThreshold(im_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,9,2)\n",
    "\n",
    "#             # 3. 进行降噪处理\n",
    "#             kernel = 1/16*np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "#             im_blur = cv2.filter2D(im_inv, -1, kernel)\n",
    "            \n",
    "            try:\n",
    "                os.mkdir('preprocessed_image')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # save it to preprocessed_image\n",
    "            path_filename2 = os.path.join('preprocessed_image', image_filename)\n",
    "            \n",
    "            cv2.imwrite(path_filename2,im_gray)\n",
    "            \n",
    "            txt += pytesseract.image_to_string(P_image.open(path_filename2),lang=\"eng\")\n",
    "            \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV\n",
    "\n",
    "这里有个问题，字体需要是黑色，背景是白色，反过来是不行的。\n",
    "\n",
    "这里简单的threshold不太好。最好的方法是locally adaptive thresholding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put the function here for future use...\n",
    "# We do not use it in INVOICE process.\n",
    "\n",
    "def pre_processing(filename):\n",
    "    # 1. 转化为灰度图\n",
    "    im = cv2.imread(directory + 'converted_image/' + filename)\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    # 2. 用adaptive threshold对图像进行二值化处理\n",
    "    im_inv = cv2.adaptiveThreshold(im_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,9,2)\n",
    "\n",
    "    # 3. 进行降噪处理\n",
    "    kernel = 1/16*np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "    im_blur = cv2.filter2D(im_inv, -1, kernel)\n",
    "\n",
    "    try:\n",
    "        os.mkdir('preprocessed_image')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # save it to preprocessed_image\n",
    "    cv2.imwrite('preprocessed_image/' + filename,im_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesseract ocr\n",
    "\n",
    "Tesseract result is really satisfying. All we need to do is preprocessing the image and run one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test codes\n",
    "print(ocr_process('test_image/03-19 AvePoint Inc. Inv 106203.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Text Extraction\n",
    "\n",
    "The layout is not as good as the OCR output, but the accuracy for words is 100%.\n",
    "\n",
    "**The next task is to know how to get a nice layout using pdfminer.**\n",
    "\n",
    "**IMPORTANT** Change char_margin to 30 if you want to match vat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "def convert_pdf_to_txt(path, line_overlap=0.5, char_margin=5, line_margin=0.5, boxes_flow=0.5):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams(line_overlap=line_overlap, char_margin=char_margin, line_margin=line_margin, word_margin=0.1, boxes_flow=boxes_flow)\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 至少两次\n",
    "# char_margin = 5 ~ 100 (100几乎就顶到pdf的头头了)\n",
    "# char_margin 的调节可以解决，行内，非box隔开字符的问题，e.g. Total amount\n",
    "\n",
    "# 这个也是至少两次\n",
    "# line_margin .5 ~ 1，box_flow<=1 可以更好的识别address\n",
    "# line_margin = 5 也可以把行都去掉了，把它变小到0.5可以解决box问题\n",
    "# boxes_flow = 0.5 ~ 5\n",
    "# boxes_flow = 5 可以把所有字符挤在一起\n",
    "# box > 1.5 line > 1.5 所有的字儿就变成一行了\n",
    "\n",
    "# 一共四种设定\n",
    "# char_margin, line_margin, box_flow\n",
    "# argu = [(5, .5, 5), (100, 1,5 ),(5, 1.5, 1.5)]\n",
    "\n",
    "# print(convert_pdf_to_txt('test_image/03-19 AvePoint Inc. Inv 106203.pdf',\\\n",
    "#                          line_overlap=.5,char_margin=100, line_margin=0.5, boxes_flow=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.pdf会出现一堆下面这种符号，无法识别\n",
    "(cid:1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Regex and Levenshtein together. \n",
    "\n",
    "TODO: Levenshtein for amount, vat and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>amount</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   string  amount  rating\n",
       "0       1       2       3\n",
       "1       1       2       3\n",
       "2       1       2       3\n",
       "5       1       2       3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-43-4a7f0c4df064>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-4a7f0c4df064>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    return df\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def amount_checker(regex_findall,distance_str):\n",
    "    '''\n",
    "    This is the function to check for amount,\n",
    "    based on different criteria.\n",
    "    \n",
    "    1. regex criteria\n",
    "    2. levenshtein rating criteria\n",
    "    \n",
    "    return a dataframe\n",
    "    '''\n",
    "    rating_ls = []\n",
    "    amount_ls = []\n",
    "    counter = 0\n",
    "    \n",
    "    df = pd.DataFrame(columns=['string','amount','rating'])\n",
    "    \n",
    "    for ind, item in enumerate(regex_findall):\n",
    "        if ('tax' in item.lower()) or ('last' in item.lower()):\n",
    "            del regex_findall[ind]\n",
    "        else:\n",
    "            amount = re.search('[0-9]{1,15}.{1,15}[0-9]{2}',item)\n",
    "            \n",
    "            if amount is not None:\n",
    "            \n",
    "                rating = distance(distance_str, item.lower())\n",
    "                rating_ls.append(rating)\n",
    "\n",
    "                amount = amount.group(0).replace(',','')\n",
    "                amount_ls.append(amount)\n",
    "                \n",
    "                # record it in the dataframe\n",
    "                df.loc[counter] = [item,amount,rating]\n",
    "                \n",
    "                counter += 1\n",
    "    \n",
    "    if len(regex_findall) > 0:\n",
    "#         print(tabulate(df.sort_values(by='rating',ascending=True),headers=('string','amount','rating'),tablefmt='psql'))\n",
    "#                 print('The string is: {}'.format(item))\n",
    "#                 print('The amount is: {}'.format(amount))\n",
    "#                 print('The rating is: {}'.format(rating))\n",
    "#                 print('-'*20)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leven_amount(txt):\n",
    "    '''\n",
    "    This is a warpper for amount_checker.\n",
    "    In here, three kinds of amount are checked.\n",
    "    '''\n",
    "    amount_str_ls = re.findall('(?<!Tax )(?<!Sub)(?<!Sub )(Total[^0-9]{1,30}[0-9,]*\\.\\d\\d)', txt, re.IGNORECASE)\n",
    "    amount_df = amount_checker(amount_str_ls,\"Grand Total: USD \\$%d.%d\".lower())\n",
    "    \n",
    "    balance_str_ls = re.findall('(?<!Previous )(?<!Prior )(?<!Ending )(?<!Past Due )(Balance[^0-9]{1,30}[0-9,]*\\.\\d\\d)', txt, re.IGNORECASE)\n",
    "    balance_df = amount_checker(balance_str_ls,\"Balance due: USD \\$%d.%d\".lower())\n",
    "\n",
    "    due_str_ls = re.findall('(Amount Due[^0-9]{1,30}[0-9,]*\\.\\d\\d)', txt, re.IGNORECASE)\n",
    "    due_df = amount_checker(due_str_ls,\"Amount due: USD \\$%d.%d\".lower())\n",
    "\n",
    "    # add a column for each one above\n",
    "    if len(amount_df) !=0:\n",
    "        amount_df.loc[:,\"Criteria\"] = \"Amount\"\n",
    "    if len(balance_df) !=0:\n",
    "        balance_df.loc[:,\"Criteria\"] = \"Balance\"\n",
    "    if len(due_df) !=0:\n",
    "        due_df.loc[:,\"Criteria\"] = \"Due\"\n",
    "    \n",
    "    # append them all\n",
    "    df = amount_df.append([balance_df,due_df])\n",
    "    \n",
    "    print(\"amount analysis end\")\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  4\n",
       "4  5\n",
       "5  6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame({\n",
    "    'a':[1,2,3]\n",
    "})\n",
    "\n",
    "b = pd.DataFrame({\n",
    "    'a':[4,5,6]\n",
    "})\n",
    "\n",
    "c = a.append(b).reset_index()\n",
    "c.drop(columns='index',inplace=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,020.17'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('[0-9]{1,15}.{1,15}[0-9]{2}','Total Amount Due: $ 1,020.17').group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Total Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def reg_amount(txt):\n",
    "\n",
    "    # prepare three kinds of amount\n",
    "    amount_due = re.findall('Due[^0-9]*\\$\\s*[0-9,]*\\.\\d\\d', txt, re.IGNORECASE)\n",
    "    amount_pay = re.findall('Pay[^0-9]*\\$\\s*[0-9,]*\\.\\d\\d', txt, re.IGNORECASE)\n",
    "    amount_total = re.findall('Total[^0-9]*\\$\\s*[0-9,]*\\.\\d\\d', txt, re.IGNORECASE)\n",
    "    pure_amount = re.findall('\\$\\s*[0-9,]*\\.\\d\\d', txt, re.IGNORECASE)\n",
    "\n",
    "    # BlaBlaBla\n",
    "    amount_ls = []\n",
    "    counter = 0\n",
    "    \n",
    "    try:\n",
    "        for i in (amount_due, amount_pay, amount_total, pure_amount):\n",
    "            for amount in i:\n",
    "                amount_ls.append(float(amount.replace(',','').split('$')[1]))\n",
    "                counter += 1\n",
    "\n",
    "        print(amount_ls)\n",
    "        print(''*20)\n",
    "\n",
    "        print('The most common amount in the list is: {}'.format(most_common(amount_ls)))\n",
    "        print('The maximum amount in the list is: {}'.format(max(amount_ls)))\n",
    "    except:\n",
    "        print(\"parse amount error\")\n",
    "    \n",
    "#     return max(amount_ls), most_common(amount_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Net & Vat\n",
    "\n",
    "<span style='color:purple'>还没有好例子呢。需要继续搞！EMEA需要</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Date\n",
    "- <span style='color:red'>Due date\n",
    "- Invoice date\n",
    "- Bill date\n",
    "- <span style='color:red'>Statement date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "\n",
    "def regex_date(txt):\n",
    "    \n",
    "    bill_date = re.findall('(?<=Bill Date)[^a-zA-Z]*.*\\d\\d\\d\\d.*(?=\\s)', txt, re.IGNORECASE)\n",
    "    invoice_date = re.findall('(?<=Invoice Date)[^a-zA-Z]*.*\\d\\d\\d\\d.*(?=\\s)', txt, re.IGNORECASE)\n",
    "    try:\n",
    "        for ind, i in enumerate(bill_date):\n",
    "            bill_date[ind] = parse(i.replace(':','').strip()).strftime(\"%m/%d/%Y\")\n",
    "        for ind, i in enumerate(invoice_date):\n",
    "            invoice_date[ind] = parse(i.replace(':','').strip()).strftime(\"%m/%d/%Y\")\n",
    "    except:\n",
    "        print(\"parse date error!\")\n",
    "\n",
    "    print(bill_date)\n",
    "    print(invoice_date)\n",
    "\n",
    "    if len(bill_date) != 0:\n",
    "        print('The most common Bill Date in the list is: {}'.format(most_common(bill_date)))\n",
    "    if len(invoice_date) != 0:\n",
    "        print('The most common Invoice Date in the list is: {}'.format(most_common(invoice_date)))\n",
    "        \n",
    "#     return most_common(bill_date), most_common(invoice_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Invoice # or Account #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def regex_invoice_number(txt):\n",
    "    invoice_number = re.findall('INVOICE[^0-9]*\\d\\d\\d[^a-zA-Z]*', txt, re.IGNORECASE)\n",
    "    account_number = re.findall('Account[^0-9]*\\d\\d\\d[^a-zA-Z]*', txt, re.IGNORECASE)\n",
    "    customer_number = re.findall('Customer[^0-9]*\\d\\d\\d[^a-zA-Z]*', txt, re.IGNORECASE)\n",
    "    ref_number = re.findall('Reference[^0-9]*\\d\\d\\d[^a-zA-Z]*', txt, re.IGNORECASE)\n",
    "    sales_order_number = re.findall('Sales order[^0-9]*\\d\\d\\d[^a-zA-Z]*', txt, re.IGNORECASE)\n",
    "\n",
    "\n",
    "    def number_checker(regex,name):\n",
    "        for ind, i in enumerate(regex):\n",
    "            regex[ind] = re.search(\"\\d.*\\d\", regex[ind]).group(0)\n",
    "\n",
    "        print('{} list: {}'.format(name,regex))\n",
    "\n",
    "        if len(regex) != 0:\n",
    "            print('The most common {} in the list is: {}'.format(name,most_common(regex)))\n",
    "\n",
    "        print('-'*20)\n",
    "        \n",
    "#         return most_common(regex)\n",
    "\n",
    "    number_checker(invoice_number,'invoice number')\n",
    "    number_checker(account_number,'account number')\n",
    "    number_checker(customer_number,'customer number')\n",
    "    number_checker(ref_number,'reference number')\n",
    "    number_checker(sales_order_number,'sales order number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Vendor Name\n",
    "\n",
    "- Vendor Name\n",
    "- Vendor Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Vendor Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def regex_vendor_address(txt):\n",
    "    vendor_address = re.findall('.{1,30}\\n\\d{1,30}.{1,30}\\n.{1,30}\\n.{1,15}\\n.{1,30}', txt, re.IGNORECASE)\n",
    "    if len(vendor_address) != 0:\n",
    "        common_address = most_common(vendor_address)\n",
    "        print('-'*20)\n",
    "        print(common_address)\n",
    "        print('-'*20)\n",
    "\n",
    "        vendor_name = common_address.splitlines()[0]\n",
    "        print(vendor_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Vendor Remittance Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def regex_remittance(txt):\n",
    "    for i in re.findall('To.*\\n.{1,30}\\n.{1,30}\\n.{1,30}\\n.{1,15}', txt, re.IGNORECASE):\n",
    "        print(i)\n",
    "        print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### NS Vendor Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "#     df = pd.read_excel('reference/vendor.xlsx')\n",
    "#     df.dropna(inplace=True)\n",
    "#     df['Full Name'] = df.apply(lambda x: str(x['ID']) + ' ' + x['Name'], axis=1)\n",
    "#     df.set_index('Name',inplace=True)\n",
    "\n",
    "#     fuzz_result = process.extract('Harvard Services Group, Inc.',df.index,limit=3)\n",
    "#     result_ls = []\n",
    "\n",
    "#     for i in fuzz_result:\n",
    "#         result_ls.append(df.loc[i[0],'Full Name'])\n",
    "\n",
    "#     for i in result_ls:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### AvePoint Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEMO for pdfminer:\n",
    "\n",
    "char_margin = 5 ~ 100 (100几乎就顶到pdf的头头了)\n",
    "\n",
    "char_margin 的调节可以解决，行内，非box隔开字符的问题，e.g. Total amount\n",
    "\n",
    "line_margin .5 ~ 1，box_flow<=1 可以更好的识别address\n",
    "\n",
    "line_margin = 5 也可以把行都去掉了，把它变小到0.5可以解决box问题\n",
    "\n",
    "boxes_flow = 0.5 ~ 5\n",
    "\n",
    "boxes_flow = 5 可以把所有字符挤在一起\n",
    "\n",
    "box > 1.5 line > 1.5 所有的字儿就变成一行了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_extraction(txt):\n",
    "    '''\n",
    "    This controls what functions will be run.\n",
    "    You can use this to test each function independently.\n",
    "    '''\n",
    "    return leven_amount(txt)\n",
    "#     reg_amount(txt)\n",
    "#     regex_date(txt)\n",
    "#     regex_vendor_address(txt)\n",
    "#     regex_remittance(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing pdf 03-19 AvePoint Inc. Inv 106203.pdf...\n",
      "Starting PDFminer process...\n",
      "Performing option 1 for pdfminer\n",
      "amount analysis end\n",
      "Performing option 2 for pdfminer\n",
      "amount analysis end\n",
      "Performing option 3 for pdfminer\n",
      "amount analysis end\n",
      "Starting ocr process...\n",
      "+----+--------------------------+----------+----------+\n",
      "|    | string                   |   amount |   rating |\n",
      "|----+--------------------------+----------+----------|\n",
      "|  0 | Balance Due: |$ 1,241.35 |  1241.35 |       10 |\n",
      "+----+--------------------------+----------+----------+\n",
      "amount analysis end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\py3.6\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-7179c4a531ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtem_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtablefmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'psql'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "# Main Loop\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "# set your working directory\n",
    "directory = 'D:/Desktop Folders/Projects/computer_vision/'\n",
    "\n",
    "# reference for pdfminer loop\n",
    "argu = [(5, 0.5, 5), (100, 1, 5),(5, 1.5, 1.5)]\n",
    "\n",
    "# main loop\n",
    "for filename in os.listdir(directory + 'test_image/'): \n",
    "    \n",
    "    print('Analysing pdf {}...'.format(filename))\n",
    "    \n",
    "    # If it's a pdf file, then...\n",
    "    if filename.endswith(\".pdf\"): \n",
    "        print('Starting PDFminer process...')\n",
    "        pdfminer_counter = 1\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        # Looping three times with different settings\n",
    "        for i, j, k in argu:\n",
    "            print('Performing option {} for pdfminer'.format(pdfminer_counter))\n",
    "            txt = convert_pdf_to_txt(directory + 'test_image/' + filename, char_margin=i, line_margin=j, boxes_flow=k)\n",
    "            \n",
    "            tem_df = regex_extraction(txt)\n",
    "            if tem_df is not None:\n",
    "                tem_df.loc[:,\"Process\"] = \"PDF Miner option {}\".format(pdfminer_counter)\n",
    "            \n",
    "            # Append all DataFrames together\n",
    "            if df is None:\n",
    "                df = tem_df\n",
    "            else:\n",
    "                df = df.append(tem_df)\n",
    "            \n",
    "            \n",
    "            \n",
    "            pdfminer_counter += 1\n",
    "\n",
    "        print('Starting ocr process...')\n",
    "        txt = ocr_process(directory + 'test_image/' +filename)\n",
    "        \n",
    "        tem_df = regex_extraction(txt)\n",
    "        if tem_df is not None:\n",
    "            tem_df.loc[:,\"Process\"] = \"OCR process\"\n",
    "        \n",
    "        # Append all DataFrames together\n",
    "        if len(df) == 0:\n",
    "            df = tem_df\n",
    "        else:\n",
    "            df = df.append(tem_df)\n",
    "        \n",
    "        print(tabulate(df.sort_values(by='rating'),tablefmt='psql'))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    else: # if it's not a pdf file\n",
    "        txt = ocr_process('test_image/' + filname) # We use a OCR process\n",
    "        regex_extraction(txt)\n",
    "        \n",
    "    print(\"-\"*20 + \"\\n\")\n",
    "\n",
    "\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "541.117px",
    "left": "1162.97px",
    "top": "111.133px",
    "width": "277.033px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
